{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/miniconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/ubuntu/miniconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/ubuntu/miniconda2/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import glob, os, gc, sys\n",
    "import os.path\n",
    "import csv\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from time import time\n",
    "from subprocess import (call, Popen, PIPE)\n",
    "from itertools import product\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "from IPython.display import Image as IPImage\n",
    "import shutil\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten,Input\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Lambda, concatenate\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, CSVLogger, EarlyStopping, TensorBoard\n",
    "from keras import Model\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras.models import load_model\n",
    "import uuid\n",
    "import pickle\n",
    "from boto3.session import Session\n",
    "import boto3\n",
    "import h5py\n",
    "\n",
    "basepath = \"/home/ubuntu/\"\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "model = load_model(os.path.join(basepath,\"LongBoard_Train_AllImages.h5\"))\n",
    "\n",
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 2] No such file or directory: '/home/ubuntu/Images_10K'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d90933e3d61b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0mdata_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrescale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.33\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0mtrain_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow_from_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasepath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Images_10K\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"training\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_height\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0mvalidation_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow_from_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasepath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Images_10K\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"validation\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_height\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/miniconda2/lib/python2.7/site-packages/keras_preprocessing/image/image_data_generator.pyc\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation)\u001b[0m\n\u001b[1;32m    536\u001b[0m             \u001b[0mfollow_links\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_links\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m             \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 538\u001b[0;31m             \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m         )\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/miniconda2/lib/python2.7/site-packages/keras_preprocessing/image/directory_iterator.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 2] No such file or directory: '/home/ubuntu/Images_10K'"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import glob, os, gc, sys\n",
    "import os.path\n",
    "import csv\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from time import time\n",
    "from subprocess import (call, Popen, PIPE)\n",
    "from itertools import product\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "from IPython.display import Image as IPImage\n",
    "import shutil\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten,Input\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Lambda, concatenate\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, CSVLogger, EarlyStopping, TensorBoard\n",
    "from keras import Model\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras.models import load_model\n",
    "import uuid\n",
    "import pickle\n",
    "from boto3.session import Session\n",
    "import boto3\n",
    "import h5py\n",
    "\n",
    "basepath = \"/home/ubuntu/\"\n",
    "epochs = 50\n",
    "batch_size = 32\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 512, 512\n",
    "\n",
    "data_generator = ImageDataGenerator(rescale=1./255, validation_split=0.33)\n",
    "train_generator = data_generator.flow_from_directory(os.path.join(basepath,\"Images_10K\"), shuffle=True, seed=13, class_mode='categorical', batch_size=batch_size, subset=\"training\", target_size=(img_width, img_height))\n",
    "validation_generator = data_generator.flow_from_directory(os.path.join(basepath,\"Images_10K\"), shuffle=True, seed=13, class_mode='categorical', batch_size=batch_size, subset=\"validation\", target_size=(img_width, img_height))\n",
    "\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "logs_base_dir = \"./logs\"\n",
    "checkpoint = ModelCheckpoint(\"first_try.h5\", monitor='loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='loss', patience=10, verbose=1, mode='auto')\n",
    "csv_logger = CSVLogger('first_try.log', append=True, separator=';')\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=validation_generator.n//validation_generator.batch_size\n",
    "model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    callbacks = [early,checkpoint,csv_logger],\n",
    "                    epochs=epochs,\n",
    "                    verbose = 1)\n",
    "\n",
    "model.save_weights('first_try.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import glob, os, gc, sys\n",
    "import os.path\n",
    "import csv\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from time import time\n",
    "from subprocess import (call, Popen, PIPE)\n",
    "from itertools import product\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "from IPython.display import Image as IPImage\n",
    "import shutil\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten,Input\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Lambda, concatenate\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, CSVLogger, EarlyStopping, TensorBoard\n",
    "from keras import Model\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras.models import load_model\n",
    "import uuid\n",
    "import pickle\n",
    "from boto3.session import Session\n",
    "import boto3\n",
    "import h5py\n",
    "from keras import applications\n",
    "\n",
    "basepath = \"/home/ubuntu/\"\n",
    "\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 512, 512\n",
    "\n",
    "top_model_weights_path = os.path.join(basepath,'bottleneck_fc_model_weights.h5')\n",
    "epochs = 50\n",
    "batch_size = 32\n",
    "logs_base_dir = \"./logs\"\n",
    "checkpoint = ModelCheckpoint(\"bottleneck_fc_model.h5\", monitor='loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='loss', patience=10, verbose=1, mode='auto')\n",
    "csv_logger = CSVLogger('bottleneck_fc_model.log', append=True, separator=';')\n",
    "\n",
    "\n",
    "data_generator = ImageDataGenerator(rescale=1./255, validation_split=0.33)\n",
    "\n",
    "# build the VGG16 network\n",
    "model = applications.InceptionV3(include_top=False, weights='imagenet')\n",
    "\n",
    "train_generator = data_generator.flow_from_directory(\n",
    "    os.path.join(basepath,\"Images_10K\"),\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False,\n",
    "    seed=13,\n",
    "    subset=\"training\")\n",
    "bottleneck_features_train = model.predict_generator(\n",
    "    train_generator, train_generator.n//train_generator.batch_size)\n",
    "np.save(open('bottleneck_features_train.npy', 'w'),bottleneck_features_train)\n",
    "\n",
    "validation_generator = data_generator.flow_from_directory(\n",
    "    os.path.join(basepath,\"Images_10K\"),\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False,\n",
    "    seed=13,\n",
    "    subset=\"validation\")\n",
    "bottleneck_features_validation = model.predict_generator(\n",
    "    validation_generator, validation_generator.n//validation_generator.batch_size)\n",
    "np.save(open('bottleneck_features_validation.npy', 'w'),bottleneck_features_validation)\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "train_data = np.load(open('bottleneck_features_train.npy'))\n",
    "train_labels = np.array(\n",
    "    [0] * (len(train_data) / 2) + [1] * (len(train_data) / 2))\n",
    "\n",
    "validation_data = np.load(open('bottleneck_features_validation.npy'))\n",
    "validation_labels = np.array(\n",
    "    [0] * (len(validation_data) / 2) + [1] * (len(validation_data) / 2))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_data, train_labels,\n",
    "          callbacks = [early,checkpoint,csv_logger],\n",
    "          epochs=epochs,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(validation_data, validation_labels))\n",
    "model.save_weights(top_model_weights_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels[1:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
