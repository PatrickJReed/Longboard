{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import glob, os, gc, sys\n",
    "import os.path\n",
    "import csv\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from time import time\n",
    "from subprocess import (call, Popen, PIPE)\n",
    "from itertools import product\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "from IPython.display import Image as IPImage\n",
    "import shutil\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten,Input\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Lambda, concatenate\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, CSVLogger, EarlyStopping, TensorBoard\n",
    "from keras import Model\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras.models import load_model\n",
    "import uuid\n",
    "import pickle\n",
    "from boto3.session import Session\n",
    "import boto3\n",
    "import h5py\n",
    "\n",
    "basepath = \"/home/ubuntu/\"\n",
    "\n",
    "batch_size = 64\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 512, 512\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "model = load_model(os.path.join(basepath,\"LongBoard_Train_AllImages.h5\"))\n",
    "\n",
    "#from keras.utils import plot_model\n",
    "#plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = ImageDataGenerator(rescale=1./255, validation_split=0.3)\n",
    "train_generator = data_generator.flow_from_directory(os.path.join(basepath,Images), shuffle=True, seed=13, class_mode='categorical', batch_size=batch_size, subset=training, target_size=(img_width, img_height))\n",
    "validation_generator = data_generator.flow_from_directory(os.path.join(basepath,Images), shuffle=True, seed=13, class_mode='categorical', batch_size=batch_size, subset=validation, target_size=(img_width, img_height))\n",
    "\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "logs_base_dir = ./logs\n",
    "checkpoint = ModelCheckpoint(LongBoard_Train_AllImages.h5, monitor='loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='loss', patience=10, verbose=1, mode='auto')\n",
    "csv_logger = CSVLogger('LongBoard_Train_AllImages.log', append=True, separator=';')\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_weight_list = compute_class_weight('balanced', np.unique(train_generator.classes), train_generator.classes)\n",
    "class_weight = dict(zip(np.unique(train_generator.classes), class_weight_list))\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=validation_generator.n//validation_generator.batch_size\n",
    "model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    callbacks = [early,checkpoint,csv_logger],\n",
    "                    epochs=epochs,\n",
    "                    class_weight=class_weight,\n",
    "                    verbose = 1)\n",
    "\n",
    "model.save_weights('LongBoard_Train_AllImages.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model(os.path.join(basepath,'LongBoard_Train_AllImages.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        os.path.join(basepath,\"Test_Images\"),\n",
    "        target_size=(512, 512),\n",
    "        color_mode=rgb,\n",
    "        shuffle = False,\n",
    "        class_mode='categorical',\n",
    "        batch_size=64)\n",
    "\n",
    "filenames = test_generator.filenames\n",
    "nb_samples = len(filenames)\n",
    "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
    "Y_pred = model.predict_generator(test_generator, STEP_SIZE_TEST, verbose=1)\n",
    "y_pred = np.argmax(Y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_generator.classes[412700:412736])\n",
    "print(Y_pred[412700:412736])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print('Confusion Matrix')\n",
    "cm = confusion_matrix(test_generator.classes[:412736], y_pred[:412736])\n",
    "print(confusion_matrix(test_generator.classes[:412736], y_pred[:412736]))\n",
    "print('Classification Report')\n",
    "target_names = ['L1HS', 'L1PA2', 'Noise', 'NonReference']\n",
    "print(classification_report(test_generator.classes[:412736], y_pred[:412736], target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "from matplotlib.collections import QuadMesh\n",
    "import seaborn as sn\n",
    "\n",
    "\n",
    "def get_new_fig(fn, figsize=[9,9]):\n",
    "     Init graphics \n",
    "    fig1 = plt.figure(fn, figsize)\n",
    "    ax1 = fig1.gca()   #Get Current Axis\n",
    "    ax1.cla() # clear existing plot\n",
    "    return fig1, ax1\n",
    "#\n",
    "\n",
    "def configcell_text_and_colors(array_df, lin, col, oText, facecolors, posi, fz, fmt, show_null_values=0):\n",
    "\n",
    "      config cell text and colors\n",
    "      and return text elements to add and to dell\n",
    "      @TODO: use fmt\n",
    "\n",
    "    text_add = []; text_del = [];\n",
    "    cell_val = array_df[lin][col]\n",
    "    tot_all = array_df[-1][-1]\n",
    "    per = (float(cell_val) / tot_all) * 100\n",
    "    curr_column = array_df[:,col]\n",
    "    ccl = len(curr_column)\n",
    "\n",
    "    #last line  and/or last column\n",
    "    if(col == (ccl - 1)) or (lin == (ccl - 1)):\n",
    "        #tots and percents\n",
    "        if(cell_val != 0):\n",
    "            if(col == ccl - 1) and (lin == ccl - 1):\n",
    "                tot_rig = 0\n",
    "                for i in range(array_df.shape[0] - 1):\n",
    "                    tot_rig += array_df[i][i]\n",
    "                per_ok = (float(tot_rig) / cell_val) * 100\n",
    "            elif(col == ccl - 1):\n",
    "                tot_rig = array_df[lin][lin]\n",
    "                per_ok = (float(tot_rig) / cell_val) * 100\n",
    "            elif(lin == ccl - 1):\n",
    "                tot_rig = array_df[col][col]\n",
    "                per_ok = (float(tot_rig) / cell_val) * 100\n",
    "            per_err = 100 - per_ok\n",
    "        else:\n",
    "            per_ok = per_err = 0\n",
    "\n",
    "        per_ok_s = ['%.2f%%'%(per_ok), '100%'] [per_ok == 100]\n",
    "\n",
    "        #text to DEL\n",
    "        text_del.append(oText)\n",
    "\n",
    "        #text to ADD\n",
    "        font_prop = fm.FontProperties(weight='bold', size=fz)\n",
    "        text_kwargs = dict(color='w', ha=center, va=center, gid='sum', fontproperties=font_prop)\n",
    "        lis_txt = ['%d'%(cell_val), per_ok_s, '%.2f%%'%(per_err)]\n",
    "        lis_kwa = [text_kwargs]\n",
    "        dic = text_kwargs.copy(); dic['color'] = 'g'; lis_kwa.append(dic);\n",
    "        dic = text_kwargs.copy(); dic['color'] = 'r'; lis_kwa.append(dic);\n",
    "        lis_pos = [(oText._x, oText._y-0.3), (oText._x, oText._y), (oText._x, oText._y+0.3)]\n",
    "        for i in range(len(lis_txt)):\n",
    "            newText = dict(x=lis_pos[i][0], y=lis_pos[i][1], text=lis_txt[i], kw=lis_kwa[i])\n",
    "            #print 'lin: %s, col: %s, newText: %s' %(lin, col, newText)\n",
    "            text_add.append(newText)\n",
    "        #print '\\\\n'\n",
    "\n",
    "        #set background color for sum cells (last line and last column)\n",
    "        carr = [0.27, 0.30, 0.27, 1.0]\n",
    "        if(col == ccl - 1) and (lin == ccl - 1):\n",
    "            carr = [0.17, 0.20, 0.17, 1.0]\n",
    "        facecolors[posi] = carr\n",
    "\n",
    "    else:\n",
    "        if(per > 0):\n",
    "            txt = '%s\\\\n%.2f%%' %(cell_val, per)\n",
    "        else:\n",
    "            if(show_null_values == 0):\n",
    "                txt = ''\n",
    "            elif(show_null_values == 1):\n",
    "                txt = '0'\n",
    "            else:\n",
    "                txt = '0\\\\n0.0%'\n",
    "        oText.set_text(txt)\n",
    "\n",
    "        #main diagonal\n",
    "        if(col == lin):\n",
    "            #set color of the textin the diagonal to white\n",
    "            oText.set_color('w')\n",
    "            # set background color in the diagonal to blue\n",
    "            facecolors[posi] = [0.35, 0.8, 0.55, 1.0]\n",
    "        else:\n",
    "            oText.set_color('r')\n",
    "\n",
    "    return text_add, text_del\n",
    "#\n",
    "\n",
    "def insert_totals(df_cm):\n",
    "     insert total column and line (the last ones) \n",
    "    sum_col = []\n",
    "    for c in df_cm.columns:\n",
    "        sum_col.append( df_cm[c].sum() )\n",
    "    sum_lin = []\n",
    "    for item_line in df_cm.iterrows():\n",
    "        sum_lin.append( item_line[1].sum() )\n",
    "    df_cm['sum_lin'] = sum_lin\n",
    "    sum_col.append(np.sum(sum_lin))\n",
    "    df_cm.loc['sum_col'] = sum_col\n",
    "    #print ('\\\\ndf_cm:\\\\n', df_cm, '\\\\n\\\\b\\\\n')\n",
    "#\n",
    "\n",
    "def pretty_plot_confusion_matrix(df_cm, annot=True, cmap=Oranges, fmt='.2f', fz=11,\n",
    "      lw=0.5, cbar=False, figsize=[8,8], show_null_values=0, pred_val_axis='y'):\n",
    "\n",
    "      print conf matrix with default layout (like matlab)\n",
    "      params:\n",
    "        df_cm          dataframe (pandas) without totals\n",
    "        annot          print text in each cell\n",
    "        cmap           Oranges,Oranges_r,YlGnBu,Blues,RdBu, ... see:\n",
    "        fz             fontsize\n",
    "        lw             linewidth\n",
    "        pred_val_axis  where to show the prediction values (x or y axis)\n",
    "                        'col' or 'x': show predicted values in columns (x axis) instead lines\n",
    "                        'lin' or 'y': show predicted values in lines   (y axis)\n",
    "\n",
    "    if(pred_val_axis in ('col', 'x')):\n",
    "        xlbl = 'Predicted'\n",
    "        ylbl = 'Actual'\n",
    "    else:\n",
    "        xlbl = 'Actual'\n",
    "        ylbl = 'Predicted'\n",
    "        df_cm = df_cm.T\n",
    "\n",
    "    # create Total column\n",
    "    insert_totals(df_cm)\n",
    "\n",
    "    #this is for print allways in the same window\n",
    "    fig, ax1 = get_new_fig('Conf matrix default', figsize)\n",
    "\n",
    "    #thanks for seaborn\n",
    "    ax = sn.heatmap(df_cm, annot=annot, annot_kws={size: fz}, linewidths=lw, ax=ax1,\n",
    "                    cbar=cbar, cmap=cmap, linecolor='w', fmt=fmt)\n",
    "\n",
    "    #set ticklabels rotation\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation = 45, fontsize = 10)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), rotation = 25, fontsize = 10)\n",
    "\n",
    "    # Turn off all the ticks\n",
    "    for t in ax.xaxis.get_major_ticks():\n",
    "        t.tick1On = False\n",
    "        t.tick2On = False\n",
    "    for t in ax.yaxis.get_major_ticks():\n",
    "        t.tick1On = False\n",
    "        t.tick2On = False\n",
    "\n",
    "    #face colors list\n",
    "    quadmesh = ax.findobj(QuadMesh)[0]\n",
    "    facecolors = quadmesh.get_facecolors()\n",
    "\n",
    "    #iter in text elements\n",
    "    array_df = np.array( df_cm.to_records(index=False).tolist() )\n",
    "    text_add = []; text_del = [];\n",
    "    posi = -1 #from left to right, bottom to top.\n",
    "    for t in ax.collections[0].axes.texts: #ax.texts:\n",
    "        pos = np.array( t.get_position()) - [0.5,0.5]\n",
    "        lin = int(pos[1]); col = int(pos[0]);\n",
    "        posi += 1\n",
    "        #print ('>>> pos: %s, posi: %s, val: %s, txt: %s' %(pos, posi, array_df[lin][col], t.get_text()))\n",
    "\n",
    "        #set text\n",
    "        txt_res = configcell_text_and_colors(array_df, lin, col, t, facecolors, posi, fz, fmt, show_null_values)\n",
    "\n",
    "        text_add.extend(txt_res[0])\n",
    "        text_del.extend(txt_res[1])\n",
    "\n",
    "    #remove the old ones\n",
    "    for item in text_del:\n",
    "        item.remove()\n",
    "    #append the new ones\n",
    "    for item in text_add:\n",
    "        ax.text(item['x'], item['y'], item['text'], **item['kw'])\n",
    "\n",
    "    #titles and legends\n",
    "    ax.set_title('Confusion matrix')\n",
    "    ax.set_xlabel(xlbl)\n",
    "    ax.set_ylabel(ylbl)\n",
    "    plt.tight_layout()  #set layout slim\n",
    "    plt.show()\n",
    "#\n",
    "\n",
    "def plot_confusion_matrix_from_data(y_test, predictions, columns=None, annot=True, cmap=Oranges,\n",
    "      fmt='.2f', fz=11, lw=0.5, cbar=False, figsize=[8,8], show_null_values=0, pred_val_axis='lin'):\n",
    "\n",
    "        plot confusion matrix function with y_test (actual values) and predictions (predic),\n",
    "        whitout a confusion matrix yet\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    from pandas import DataFrame\n",
    "\n",
    "    #data\n",
    "    if(not columns):\n",
    "        #labels axis integer:\n",
    "        ##columns = range(1, len(np.unique(y_test))+1)\n",
    "        #labels axis string:\n",
    "        from string import ascii_uppercase\n",
    "        columns = ['class %s' %(i) for i in list(ascii_uppercase)[0:len(np.unique(y_test))]]\n",
    "\n",
    "    confm = confusion_matrix(y_test, predictions)\n",
    "    cmap = 'Oranges';\n",
    "    fz = 11;\n",
    "    figsize=[9,9];\n",
    "    show_null_values = 2\n",
    "    df_cm = DataFrame(confm, index=columns, columns=columns)\n",
    "    pretty_plot_confusion_matrix(df_cm, fz=fz, cmap=cmap, figsize=figsize, show_null_values=show_null_values, pred_val_axis=pred_val_axis)\n",
    "#\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "#TEST functions\n",
    "#\n",
    "def _test_cm():\n",
    "    #test function with confusion matrix done\n",
    "    array = np.array( [[13,  0,  1,  0,  2,  0],\n",
    "                       [ 0, 50,  2,  0, 10,  0],\n",
    "                       [ 0, 13, 16,  0,  0,  3],\n",
    "                       [ 0,  0,  0, 13,  1,  0],\n",
    "                       [ 0, 40,  0,  1, 15,  0],\n",
    "                       [ 0,  0,  0,  0,  0, 20]])\n",
    "    #get pandas dataframe\n",
    "    #df_cm = DataFrame(array, index=range(1,7), columns=range(1,7))\n",
    "    df_cm = DataFrame(cm, index=target_names, columns=target_names)\n",
    "    #colormap: see this and choose your more dear\n",
    "    cmap = 'PuRd'\n",
    "    pretty_plot_confusion_matrix(df_cm, cmap=cmap)\n",
    "#\n",
    "\n",
    "#\n",
    "#MAIN function\n",
    "#\n",
    "if(__name__ == '__main__'):\n",
    "    print('__main__')\n",
    "    print('_test_cm: test function with confusion matrix done\\\\nand pause')\n",
    "    _test_cm()\n",
    "    plt.pause(5)\n",
    "    print('_test_data_class: test function with y_test (actual values) and predictions (predic)')\n",
    "    _test_data_class()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CompleteOverlap = /home/ubuntu/longboard/hs37d5_15K_Windows_CompleteFinal.txt\n",
    "AnyOverlap = /home/ubuntu/longboard/hs37d5_15K_Windows_AnyFinal.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ref_Complete = {}\n",
    "with open(CompleteOverlap) as fin1:\n",
    "    rows = ( line.strip().split('\\\\t') for line in fin1 )\n",
    "    for row in rows:\n",
    "        Ref_Complete[row[0]] = {}\n",
    "        Ref_Complete[row[0]]['L1HS'] = row[1]\n",
    "        Ref_Complete[row[0]]['L1PA2'] = row[2]\n",
    "        Ref_Complete[row[0]]['L1PA3'] = row[3]\n",
    "        Ref_Complete[row[0]]['L1PA4'] = row[4]\n",
    "        Ref_Complete[row[0]]['L1PA5'] = row[5]\n",
    "        Ref_Complete[row[0]]['L1Other'] = row[6]\n",
    "        Ref_Complete[row[0]]['eul1db_mrip'] = row[7]\n",
    "Ref_Any = {}\n",
    "with open(AnyOverlap) as fin2:\n",
    "    rows = ( line.strip().split('\\\\t') for line in fin2 )\n",
    "    for row in rows:\n",
    "        Ref_Any[row[0]] = {}\n",
    "        Ref_Any[row[0]]['L1HS'] = row[1]\n",
    "        Ref_Any[row[0]]['L1PA2'] = row[2]\n",
    "        Ref_Any[row[0]]['L1PA3'] = row[3]\n",
    "        Ref_Any[row[0]]['L1PA4'] = row[4]\n",
    "        Ref_Any[row[0]]['L1PA5'] = row[5]\n",
    "        Ref_Any[row[0]]['L1Other'] = row[6]\n",
    "        Ref_Any[row[0]]['eul1db_mrip'] = row[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T={}\n",
    "for i in range(0,412736):\n",
    "    if y_pred[i] == 3:\n",
    "        position_key = filenames[i].strip().split('-')[1].split('_mod')[0]\n",
    "        if position_key not in T:\n",
    "            cell_id = filenames[i].strip().split('-')[0]\n",
    "            T[position_key] = {}\n",
    "            T[position_key]['Ref_Partial'] = {}\n",
    "            T[position_key]['Ref_Complete'] = {}  \n",
    "            T[position_key]['Ref_Partial']['eul1db_mrip'] = '0'\n",
    "            if int(Ref_Any[position_key]['eul1db_mrip']) > int(Ref_Complete[position_key]['eul1db_mrip']):\n",
    "                T[position_key]['Ref_Partial']['eul1db_mrip'] = '1'\n",
    "            T[position_key]['Ref_Complete']['eul1db_mrip'] = '0'\n",
    "            if int(Ref_Complete[position_key]['eul1db_mrip']) != 0:\n",
    "                T[position_key]['Ref_Complete']['eul1db_mrip'] = '1'                      \n",
    "        ## file name y_pred, y_pred max, cell count \n",
    "        if i == 0:\n",
    "            Labs = filenames[i]+;+position_key+;+str(test_generator.classes[i])+;+str(y_pred[i])+;+T[position_key]['Ref_Partial']['eul1db_mrip']+;+T[position_key]['Ref_Complete']['eul1db_mrip']\n",
    "        else:\n",
    "            lab= filenames[i]+;+position_key+;+str(test_generator.classes[i])+;+str(y_pred[i])+;+T[position_key]['Ref_Partial']['eul1db_mrip']+;+T[position_key]['Ref_Complete']['eul1db_mrip']\n",
    "            Labs = np.vstack((Labs,lab))\n",
    "\n",
    "print(len(Labs)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
