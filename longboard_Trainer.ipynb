{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available buckets:\n",
      "ataxia                                   2019/02/28 (19:50:42)\n",
      "bsmn-data                                2019/04/11 (17:46:28)\n",
      "karadata                                 2018/11/20 (18:48:01)\n",
      "krishna-mdd                              2018/07/27 (15:53:28)\n",
      "longboard-bulk                           2019/04/10 (19:58:42)\n",
      "longboard-sc                             2019/04/10 (19:59:09)\n",
      "metapsych                                2018/06/13 (14:13:48)\n",
      "ms-project-logg                          2018/07/27 (17:10:04)\n",
      "project-inigo                            2018/03/26 (15:20:49)\n",
      "repair-seq                               2018/07/18 (16:21:43)\n",
      "salk-logg-bsmn                           2018/01/08 (18:16:44)\n",
      "sz-project                               2018/07/27 (17:10:30)\n",
      "Current bucket: bsmn-data\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import cottoncandy as cc\n",
    "from boto3.session import Session\n",
    "import boto3\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from sklearn.cluster import DBSCAN\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.layers import Input \n",
    "from keras.preprocessing import image\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "#from keras.utils import multi_gpu_model\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Lambda, concatenate\n",
    "from keras import Model\n",
    "from keras.models import load_model\n",
    "\n",
    "subject = \"CommonSample\" #sys.argv[1]  #subjectid\n",
    "Cells = [\"04132016_mw_L1B1_SC_A2_S43\",\"04132016_mw_L1B1_SC_C1_S45\",\"04132016_mw_L1B1_SC_C2_S46\",\"04132016_mw_L1B1_SC_D2_S50\",\"04132016_mw_L1B1_SC_E2_S51\",\"04132016_mw_L1B1_SC_E3_S52\",\"04132016_mw_L1B1_SC_F2_S53\",\"04132016_mw_L1B1_SC_G1_S54\",\"04132016_mw_L1B1_SC_H1_S55\",\"05252016_mw_L1B1_SC_B4_S47\"] \n",
    "\n",
    "#cell = sys.argv[2] #input\n",
    "ACCESS_KEY = 'AKIAJNNOA6QMT7HXF6GA'\n",
    "SECRET_KEY = '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'\n",
    "cci = cc.get_interface('bsmn-data', ACCESS_KEY=ACCESS_KEY, SECRET_KEY=SECRET_KEY, endpoint_url='https://s3-us-west-2.amazonaws.com')\n",
    "\n",
    "input_tensor = Input(shape=(512, 512, 3))\n",
    "base_model = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
    "\n",
    "x=base_model.output\n",
    "x = Flatten(name='flatten')(x)\n",
    "x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "preds = Dense(512, activation='sigmoid', name='predictions')(x)\n",
    "\n",
    "feat_extractor = Model(inputs=base_model.input,outputs=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cell in Cells:\n",
    "    print(cell)\n",
    "    cell_size=0\n",
    "    cell_ids = []\n",
    "    cell_list=cci.glob(subject+'/'+cell+'/'+cell+\"*_Y.npy\")\n",
    "    for i in cell_list:   \n",
    "        leng = len(i.strip().split('_'))\n",
    "        cell_ids.append(i.strip().split('_')[leng-2])\n",
    "    print(cell_ids)\n",
    "    count = 0\n",
    "    for cid in cell_ids:\n",
    "        print(subject+'/'+cell+'/'+cell+'_'+cid+'_X.npy')\n",
    "        cci.download_raw_array('04132016_mw_L1B1_SC_A2_S43_3f58b0d9534a49ada313518576cbc7c0_X.npy', x)\n",
    "        cci.download_raw_array(subject+'/'+cell+'/'+cell+'_'+cid+'_Y.npy')\n",
    "        print(x.shape)\n",
    "        z = feat_extractor.predict(x, batch_size = 32)\n",
    "        if count == 0:\n",
    "            Z = z\n",
    "            Y = y\n",
    "        else:\n",
    "            Z = np.append(Z,z)\n",
    "            print(Z.shape)\n",
    "            Y = np.append(Y,y)\n",
    "    cci.upload_raw_array(subject+'/'+cell+'/'+cell+'_Features.npy', x, gzip=True)\n",
    "    cci.upload_raw_array(subject+'/'+cell+'/'+cell+'_Y.npy', y, gzip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from MulticoreTSNE import MulticoreTSNE as TSNE\n",
    "#from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components=2, verbose=2, perplexity=40, n_iter=3000, n_jobs=16)\n",
    "tsne_results = tsne.fit_transform(features)\n",
    "tx, ty = tsne_results[:,0], tsne_results[:,1]\n",
    "tx = (tx-np.min(tx)) / (np.max(tx) - np.min(tx))\n",
    "ty = (ty-np.min(ty)) / (np.max(ty) - np.min(ty))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (20,20)\n",
    "plt.scatter(tsne_results[:, 0], tsne_results[:, 1], alpha=0.8, s=8)\n",
    "plt.axis('equal');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(basepath,'tsneResults.npy'), tsne_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_results = np.load(os.path.join(basepath,'tsneResults.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DBSCAN(min_samples=50, eps=1.7,n_jobs=16,algorithm='auto', leaf_size=30, metric='euclidean').fit(tsne_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "core_samples_mask[db.core_sample_indices_] = True\n",
    "labels = db.labels_\n",
    "\n",
    "# Number of clusters in labels, ignoring noise if present.\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "\n",
    "unique_labels = set(labels)\n",
    "colors = [plt.cm.Spectral(each)\n",
    "          for each in np.linspace(0, 1, len(unique_labels))]\n",
    "for k, col in zip(unique_labels, colors):\n",
    "    if k == -1:\n",
    "        # Black used for noise.\n",
    "        col = [0, 0, 0, 1]\n",
    "\n",
    "    class_member_mask = (labels == k)\n",
    "\n",
    "    xy = tsne_results[class_member_mask & core_samples_mask]\n",
    "    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
    "             markeredgecolor='k', markersize=8)\n",
    "\n",
    "    xy = tsne_results[class_member_mask & ~core_samples_mask]\n",
    "    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
    "             markeredgecolor='k', markersize=1)\n",
    "plt.rcParams[\"figure.figsize\"] = (50,50)\n",
    "plt.title('Estimated number of clusters: %d' % n_clusters_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels[labels == 16].shape)\n",
    "print(tsne_results[labels == 16].shape)\n",
    "print(X[labels == 16].shape)\n",
    "labels[labels == 16].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "def visualize_scatter_with_images(X_2d_data, images, figsize=(100,100), image_zoom=.1):\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    artists = []\n",
    "    for xy, i in zip(X_2d_data, images):\n",
    "        x0, y0 = xy\n",
    "        img = OffsetImage(i, zoom=image_zoom)\n",
    "        ab = AnnotationBbox(img, (x0, y0), xycoords='data', frameon=False)\n",
    "        artists.append(ax.add_artist(ab))\n",
    "    ax.update_datalim(X_2d_data)\n",
    "    ax.autoscale()\n",
    "    plt.show()\n",
    "\n",
    "visualize_scatter_with_images(tsne_results, images = X, image_zoom=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "def visualize_scatter_with_images(X_2d_data, images, figsize=(100,100), image_zoom=1):\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    artists = []\n",
    "    for xy, i in zip(X_2d_data, images):\n",
    "        x0, y0 = xy\n",
    "        img = OffsetImage(i, zoom=image_zoom)\n",
    "        ab = AnnotationBbox(img, (x0, y0), xycoords='data', frameon=False)\n",
    "        artists.append(ax.add_artist(ab))\n",
    "    ax.update_datalim(X_2d_data)\n",
    "    ax.autoscale()\n",
    "    plt.show()\n",
    "\n",
    "visualize_scatter_with_images(tsne_results[labels == 5], images = X[labels == 5], image_zoom=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((512,512,3,200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_response1 = cci.upload_raw_array('X.npy', X, gzip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xnew = cci.download_raw_array('X.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Xnew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "right operand length must match slice length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-bbff63c38bd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcci\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_raw_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'04132016_mw_L1B1_SC_A2_S43_3f58b0d9534a49ada313518576cbc7c0_X.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/cottoncandy/utils.pyc\u001b[0m in \u001b[0;36miremove_root\u001b[0;34m(self, object_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m             \u001b[0mobject_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject_name\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0minput_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0miremove_root\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/cottoncandy/interfaces.pyc\u001b[0m in \u001b[0;36mdownload_raw_array\u001b[0;34m(self, object_name, buffersize, **kwargs)\u001b[0m\n\u001b[1;32m    644\u001b[0m             \u001b[0mdatastream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m         \u001b[0mread_buffered\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatastream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffersize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuffersize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/cottoncandy/utils.pyc\u001b[0m in \u001b[0;36mread_buffered\u001b[0;34m(frm, to, buffersize)\u001b[0m\n\u001b[1;32m    450\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes_total\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mci\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbuffersize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPY2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m             \u001b[0mto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPY3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m             \u001b[0mvw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: right operand length must match slice length"
     ]
    }
   ],
   "source": [
    "cci.download_raw_array('04132016_mw_L1B1_SC_A2_S43_3f58b0d9534a49ada313518576cbc7c0_X.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p27)",
   "language": "python",
   "name": "conda_tensorflow_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
