{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import glob, os, gc, sys\n",
    "import os.path\n",
    "import csv\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from time import time\n",
    "from subprocess import (call, Popen, PIPE)\n",
    "from itertools import product\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "from IPython.display import Image as IPImage\n",
    "import shutil\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten,Input\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Lambda, concatenate\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, CSVLogger, EarlyStopping, TensorBoard\n",
    "from keras import Model\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras.models import load_model\n",
    "import uuid\n",
    "import pickle\n",
    "from boto3.session import Session\n",
    "import boto3\n",
    "import h5py\n",
    "\n",
    "\n",
    "##Path to Data\n",
    "basepath = \"/home/ubuntu/\"\n",
    "ACCESS_KEY = 'AKIAJNNOA6QMT7HXF6GA'\n",
    "SECRET_KEY = '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'\n",
    "session = Session(aws_access_key_id=ACCESS_KEY,aws_secret_access_key=SECRET_KEY)\n",
    "s3 = session.resource('s3')\n",
    "\n",
    "img_width, img_height = 512,512\n",
    "nb_epochs = 500\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24120 images belonging to 4 classes.\n",
      "Found 11880 images belonging to 4 classes.\n",
      "WARNING:tensorflow:From /home/ubuntu/miniconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/ubuntu/miniconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "K.get_session().run(tf.global_variables_initializer())\n",
    "#TRAIN inception model on SLAV\n",
    "data_generator = ImageDataGenerator(rescale=1./255, validation_split=0.33)\n",
    "train_generator = data_generator.flow_from_directory(os.path.join(basepath,\"Images_10K\"), shuffle=True, seed=13, class_mode='categorical', batch_size=batch_size, subset=\"training\", target_size=(img_width, img_height))\n",
    "validation_generator = data_generator.flow_from_directory(os.path.join(basepath,\"Images_10K\"), shuffle=True, seed=13, class_mode='categorical', batch_size=batch_size, subset=\"validation\", target_size=(img_width, img_height))\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "\n",
    "base_model = InceptionV3(input_shape=input_shape, weights='imagenet', include_top=False)\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "x = Dropout(.5)(x)\n",
    "predictions = Dense(4, activation='softmax')(x)\n",
    "\n",
    "\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "logs_base_dir = \"./logs\"\n",
    "checkpoint = ModelCheckpoint(\"Longboard_model_Transfer.h5\", monitor='loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='loss', patience=10, verbose=1, mode='auto')\n",
    "csv_logger = CSVLogger('training_longboard_Transfer.log', append=True, separator=';')\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/miniconda2/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/5\n",
      "753/753 [==============================] - 309s 410ms/step - loss: 1.0084 - acc: 0.6384 - val_loss: 1.9140 - val_acc: 0.2503\n",
      "\n",
      "Epoch 00001: loss improved from inf to 1.00836, saving model to Longboard_model_Transfer.h5\n",
      "Epoch 2/5\n",
      "753/753 [==============================] - 306s 406ms/step - loss: 0.6136 - acc: 0.7751 - val_loss: 2.2799 - val_acc: 0.2590\n",
      "\n",
      "Epoch 00002: loss improved from 1.00836 to 0.61367, saving model to Longboard_model_Transfer.h5\n",
      "Epoch 3/5\n",
      "753/753 [==============================] - 306s 406ms/step - loss: 0.5398 - acc: 0.8028 - val_loss: 3.0328 - val_acc: 0.2514\n",
      "\n",
      "Epoch 00003: loss improved from 0.61367 to 0.53971, saving model to Longboard_model_Transfer.h5\n",
      "Epoch 4/5\n",
      "753/753 [==============================] - 305s 405ms/step - loss: 0.5140 - acc: 0.8169 - val_loss: 2.5122 - val_acc: 0.2615\n",
      "\n",
      "Epoch 00004: loss improved from 0.53971 to 0.51388, saving model to Longboard_model_Transfer.h5\n",
      "Epoch 5/5\n",
      "753/753 [==============================] - 301s 400ms/step - loss: 0.4887 - acc: 0.8245 - val_loss: 3.1996 - val_acc: 0.2629\n",
      "\n",
      "Epoch 00005: loss improved from 0.51388 to 0.48858, saving model to Longboard_model_Transfer.h5\n"
     ]
    }
   ],
   "source": [
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=validation_generator.n//validation_generator.batch_size\n",
    "model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=5,\n",
    "                    callbacks = [early,checkpoint,csv_logger], \n",
    "                    verbose = 1)\n",
    "model.save('Longboard_model_Transfer.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[:249]:\n",
    "   layer.trainable = False\n",
    "for layer in model.layers[249:]:\n",
    "   layer.trainable = True\n",
    "from keras.optimizers import SGD\n",
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "753/753 [==============================] - 310s 411ms/step - loss: 0.2861 - acc: 0.9039 - val_loss: 4.0576 - val_acc: 0.2692\n",
      "\n",
      "Epoch 00001: loss improved from 0.48858 to 0.28614, saving model to Longboard_model_Transfer.h5\n",
      "Epoch 2/100\n",
      "753/753 [==============================] - 302s 400ms/step - loss: 0.1912 - acc: 0.9385 - val_loss: 4.0220 - val_acc: 0.2670\n",
      "\n",
      "Epoch 00002: loss improved from 0.28614 to 0.19125, saving model to Longboard_model_Transfer.h5\n",
      "Epoch 3/100\n",
      "753/753 [==============================] - 300s 399ms/step - loss: 0.1580 - acc: 0.9495 - val_loss: 3.8635 - val_acc: 0.2759\n",
      "\n",
      "Epoch 00003: loss improved from 0.19125 to 0.15803, saving model to Longboard_model_Transfer.h5\n",
      "Epoch 4/100\n",
      "752/753 [============================>.] - ETA: 0s - loss: 0.1287 - acc: 0.9589"
     ]
    }
   ],
   "source": [
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=validation_generator.n//validation_generator.batch_size\n",
    "model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=100,\n",
    "                    callbacks = [early,checkpoint,csv_logger], \n",
    "                    verbose = 1)\n",
    "model.save('Longboard_model_Transfer.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
