{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os, gc\n",
    "import cottoncandy as cc\n",
    "import uuid\n",
    "import sparse\n",
    "from sparse import COO\n",
    "import os.path\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import offsetbox\n",
    "from __future__ import division\n",
    "from time import time\n",
    "from subprocess import (call, Popen, PIPE)\n",
    "from itertools import product\n",
    "from sklearn import (manifold, datasets, decomposition, ensemble, discriminant_analysis, random_projection)\n",
    "from sklearn.decomposition import (PCA, RandomizedPCA)\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.utils import shuffle\n",
    "from IPython.display import Image\n",
    "from PIL import Image\n",
    "from IPython.display import Image as IPImage\n",
    "import shutil\n",
    "#import pybedtools\n",
    "#import pysam\n",
    "import re\n",
    "import xml.etree.ElementTree as ET\n",
    "import time\n",
    "\n",
    "####convert bed to loci file\n",
    "\n",
    "##Path to Data\n",
    "basepath = \"/home/ubuntu/Analysis/\"\n",
    "cellpath = \"/home/ubuntu/Analysis/\"\n",
    "genome_regions = \"hs37d5_15K_Windows.bed\"\n",
    "L1HS = \"/home/ubuntu/Analysis/rmask_L1HS_Correct.bed\"\n",
    "L1HS_bam = \"-L1HS_mapped.bam\"\n",
    "L1HS_bam_bai = \"-L1HS_mapped.bam.bai\"\n",
    "bam = \"-ready.bam\"\n",
    "igv = \"-igv.xml\"\n",
    "bed = \".bed\"\n",
    "coverage15k = \".coverage15k\"\n",
    "coverage15k_gt100 = \".coverage15kgt100\"\n",
    "coverage15k_gt500 = \".coverage15kgt500\"\n",
    "loci = \".loci\"\n",
    "##IGV Template\n",
    "IGV = \"/home/ubuntu/Analysis/IGV_template.xml\"\n",
    "\n",
    "##Common Data\n",
    "Bulk_Brain_Common = \"04132016_mw_Bulk_cor\"\n",
    "Bulk_Fibro_Common = \"05252016_mw_Bulk_fib\"\n",
    "SC_MDA_Common = [\"04132016_mw_L1B1_SC_A2_S43\"]#,\"04132016_mw_L1B1_SC_C1_S45\",\"04132016_mw_L1B1_SC_C2_S46\",\"04132016_mw_L1B1_SC_D2_S50\",\"04132016_mw_L1B1_SC_E2_S51\",\"04132016_mw_L1B1_SC_E3_S52\",\"04132016_mw_L1B1_SC_F2_S53\",\"04132016_mw_L1B1_SC_G1_S54\",\"04132016_mw_L1B1_SC_H1_S55\",\"05252016_mw_L1B1_SC_B4_S47\"] \n",
    "\n",
    "Data_Sets = []\n",
    "Data_Sets.append([SC_MDA_Common,Bulk_Brain_Common,Bulk_Fibro_Common])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04132016_mw_L1B1_SC_A2_S43\n"
     ]
    }
   ],
   "source": [
    "##make XML file for each cell to use with igv_plotter\n",
    "for dset in Data_Sets:\n",
    "    for cell in dset[0]:\n",
    "        print cell\n",
    "        tree = ET.parse(IGV)\n",
    "        root = tree.getroot()\n",
    "        root[0][0].set('path', os.path.join(cellpath,  cell, cell + bam)) #sc bam\n",
    "        root[0][1].set('path', os.path.join(cellpath,  cell, cell + L1HS_bam)) #L1HS bam\n",
    "        root[1][0].set('id', os.path.join(cellpath,  cell, cell + bam)) #sc bam\n",
    "        root[2][0].set('id', os.path.join(cellpath,  cell, cell + L1HS_bam)) #L1HS bam\n",
    "        tree.write(os.path.join(cellpath,  cell, cell + igv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04132016_mw_L1B1_SC_A2_S43\n"
     ]
    }
   ],
   "source": [
    "for dset in Data_Sets:\n",
    "    for cell in dset[0]:\n",
    "        print cell\n",
    "        myoutput = open(os.path.join(cellpath, cell, cell + L1HS_bam), 'w')\n",
    "        p1 = Popen(['java', '-jar', '/home/ubuntu/jvarkit/dist/samviewwithmate.jar', '-b', L1HS, '--samoutputformat', 'BAM', os.path.join(cellpath,  cell, cell + bam)], stdout=myoutput)\n",
    "        p1.wait()\n",
    "        myoutput.close()\n",
    "        \n",
    "        p2 = Popen(['samtools', 'index', os.path.join(cellpath, cell, cell + L1HS_bam)])\n",
    "        p2.wait()\n",
    "        \n",
    "        myoutput2 = open(os.path.join(cellpath, cell, cell + coverage15k), 'w')\n",
    "        p3 = Popen(['bedtools', 'multicov', '-bams', os.path.join(cellpath, cell, cell + bam), '-bed', os.path.join(basepath,genome_regions)], stdout=myoutput2)\n",
    "        p3.wait()\n",
    "        myoutput2.close()\n",
    "        \n",
    "        myinput3 = open(os.path.join(cellpath, cell, cell + coverage15k), 'r')\n",
    "        myoutput3 = open(os.path.join(cellpath, cell, cell + coverage15k_gt100), 'w') \n",
    "        awk_cmd = \"{ if ($4 > 100) { print } }\"\n",
    "        proc = Popen(['awk', awk_cmd], stdin=myinput3, stdout=myoutput3)  \n",
    "        proc.wait()\n",
    "        myoutput3.flush()\n",
    "        \n",
    "        myinput_loci = os.path.join(cellpath, cell, cell + coverage15k_gt100)\n",
    "        myoutput_loci = os.path.join(cellpath, cell, cell + loci)\n",
    "        #regioncount = 0\n",
    "        with open(myoutput_loci, 'w') as outfile:\n",
    "            with open(myinput_loci, 'r') as infile:\n",
    "                data = infile.readlines()\n",
    "                for region in data:\n",
    "                    #regioncount += 1\n",
    "                    row = [str(region.strip().split('\\t')[0]),\":\",str(region.strip().split('\\t')[1]),\"-\",str(region.strip().split('\\t')[2])]  \n",
    "                    outfile.write(\"\".join(row)+'\\n')\n",
    "        #print regioncount\n",
    "        Popen(['split', '-l', '100', '-d', os.path.join(cellpath, cell, cell + loci), os.path.join(cellpath,  cell, cell + \".locisplit\")]).wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available buckets:\n",
      "ataxia                                   2019/02/28 (19:50:42)\n",
      "karadata                                 2018/11/20 (18:48:01)\n",
      "krishna-mdd                              2018/07/27 (15:53:28)\n",
      "metapsych                                2018/06/13 (14:13:48)\n",
      "ms-project-logg                          2018/07/27 (17:10:04)\n",
      "project-inigo                            2018/03/26 (15:20:49)\n",
      "repair-seq                               2018/07/18 (16:21:43)\n",
      "salk-logg-bsmn                           2018/01/08 (18:16:44)\n",
      "sz-project                               2018/07/27 (17:10:30)\n",
      "Current bucket: salk-logg-bsmn\n"
     ]
    }
   ],
   "source": [
    "cci = cc.get_interface('salk-logg-bsmn', ACCESS_KEY='AKIAJNNOA6QMT7HXF6GA', SECRET_KEY='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', endpoint_url='https://s3-us-west-1.amazonaws.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04132016_mw_L1B1_SC_A2_S43\n",
      "188\n",
      "187\n",
      "04132016_mw_L1B1_SC_A2_S43.locisplit9055\n",
      "(4, 512, 512, 3)\n",
      "(4,)\n",
      "None\n",
      "None\n",
      "None\n",
      "Done with Sample: 04132016_mw_L1B1_SC_A2_S43\n"
     ]
    }
   ],
   "source": [
    "for dset in Data_Sets:    \n",
    "    for cell in dset[0]:\n",
    "        print cell\n",
    "        cell_ids = []\n",
    "        os.chdir(os.path.join(cellpath, cell))    \n",
    "        locifile = os.path.join(cellpath, cell, cell + loci)\n",
    "        worklist = glob.glob(\"*.locisplit*\")\n",
    "        batchsize = 1\n",
    "        print len(worklist)\n",
    "        for i in xrange(187, len(worklist), batchsize):\n",
    "            batch = worklist[i:i+batchsize]\n",
    "            print i\n",
    "            index = 1\n",
    "            procs = []\n",
    "            for file in batch:\n",
    "                print file\n",
    "                with open(os.path.join(cellpath, cell, file)) as f0:\n",
    "                    first = f0.readline()# Read the first line.\n",
    "                    for last in f0: pass\n",
    "                    firstpic = cell+\"*\"+first.strip().split(':')[0]+\"_\"+first.strip().split(':')[1].split('-')[0]+\"_\"+first.strip().split(':')[1].split('-')[1]+\".png\"\n",
    "                    lastpic = cell+\"*\"+last.strip().split(':')[0]+\"_\"+last.strip().split(':')[1].split('-')[0]+\"_\"+last.strip().split(':')[1].split('-')[1]+\".png\"\n",
    "                    if not (glob.glob(os.path.join(basepath, cell, firstpic)) or glob.glob(os.path.join(basepath, cell, lastpic))): \n",
    "                        p = Popen(['igv_plotter', '-o', cell+\"_\", '-L', file, '-v', '--max-panel-height', '1000', '--igv-jar-path', '/home/ubuntu/Analysis/IGV_2.4.10/igv.jar', '-m', '6G', '-g', 'hg19', os.path.join(cellpath, cell, cell + igv)])\n",
    "                        procs.append(p)\n",
    "            for pp in procs:\n",
    "                pp.wait()\n",
    "            for file in glob.glob(\"*s*__*.png\"):\n",
    "                newfile = re.sub(\"_s\\d+__\", \"-\", file)\n",
    "                shutil.move(file, newfile)\n",
    "            for file in glob.glob(\"*.png\"):\n",
    "                if \"mod\" not in file:\n",
    "                    path = os.path.splitext(file)[0]\n",
    "                    basename = os.path.basename(path)\n",
    "                    outfile1 = basename + \"_mod.png\"\n",
    "                    if not os.path.isfile(os.path.join(cellpath,cell,outfile1)):               \n",
    "                        img = Image.open(file)\n",
    "                        pixelMap = img.load()\n",
    "                        img2 = Image.new(img.mode, img.size)\n",
    "                        pixelsNew = img2.load()\n",
    "                        for i in range(img2.size[0]):\n",
    "                            for j in range(img2.size[1]):\n",
    "                                if 250 in pixelMap[i,j]:\n",
    "                                    pixelMap[i,j] = (0,0,0,0)\n",
    "                                else:\n",
    "                                    pixelsNew[i,j] = pixelMap[i,j]\n",
    "                    img2.crop((174,130,img.size[0]-22,img.size[1])).resize((512,512)).save(outfile1)    \n",
    "            filelist = glob.glob(\"*_mod.png\")        \n",
    "            x = np.array([np.array(Image.open(fname)) for fname in filelist])\n",
    "            y = np.array([np.array(fname).astype(str) for fname in filelist])\n",
    "            uid = uuid.uuid4()\n",
    "            cell_ids.append(uid.hex)\n",
    "            print x.shape\n",
    "            print y.shape\n",
    "            s3_response1 = cci.upload_raw_array('Analysis/'+cell+'/'+cell+'_'+uid.hex+'_X.npy', x, gzip=True)\n",
    "            s3_response2 = cci.upload_raw_array('Analysis/'+cell+'/'+cell+'_'+uid.hex+'_Y.npy', y, gzip=True)\n",
    "            print s3_response1\n",
    "            print s3_response2\n",
    "            for file in glob.glob(\"*.png\"):\n",
    "                os.remove(file)\n",
    "            del x\n",
    "            del y\n",
    "            s3_response3 = cci.upload_raw_array('Analysis/'+cell+'/'+cell+'_IDs.npy', np.array(cell_ids))\n",
    "            print s3_response3\n",
    "            print \"Done with Sample: \"+cell\n",
    "            ##store unique npy ids for clarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a2c604e3dc964b428e2fe49904a96e54\n",
      "[u'0988c3c62d844e298a7599d6de8b090e', u'256c034f54814d01a022dc17b03151ea', u'4e497bbad0c54bf1a691aa2805810eac', u'63fc286da4ce43abac8d2940f83d1667', u'75c0f2bde564411a8c6fe8ba4f457549', u'9966b1fea162420a9ed98df65cbe2523', u'9b49d459778d4908b82288dda61a7864', u'a3068193440c4316a964449e0b23831a', u'b343c51ab9194fbdba1b1f136a60af6b', u'bde29400845e4761b028ae8bf319e267', u'c0cbd47b8d9046449f4d41a3e498a51e', u'cc16a6f89c6f4dfdb67d5bfc6903091a', u'faae949235654cc7956f4bd17636e83c', 'a2c604e3dc964b428e2fe49904a96e54']\n"
     ]
    }
   ],
   "source": [
    "uid = uuid.uuid4()\n",
    "print uid.hex\n",
    "cell_ids.append(uid.hex)\n",
    "print cell_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21922\n",
      "[u'0988c3c62d844e298a7599d6de8b090e', u'256c034f54814d01a022dc17b03151ea', u'4e497bbad0c54bf1a691aa2805810eac', u'63fc286da4ce43abac8d2940f83d1667', u'75c0f2bde564411a8c6fe8ba4f457549', u'9966b1fea162420a9ed98df65cbe2523', u'9b49d459778d4908b82288dda61a7864', u'a3068193440c4316a964449e0b23831a', u'b343c51ab9194fbdba1b1f136a60af6b', u'bde29400845e4761b028ae8bf319e267', u'c0cbd47b8d9046449f4d41a3e498a51e', u'cc16a6f89c6f4dfdb67d5bfc6903091a', u'faae949235654cc7956f4bd17636e83c']\n"
     ]
    }
   ],
   "source": [
    "cell = SC_MDA_Common[0]\n",
    "cell_size=0\n",
    "cell_ids = []\n",
    "cell_list=cci.glob(\"Analysis/\"+cell+\"*_Y.npy\")\n",
    "for i in cell_list:   \n",
    "    leng = len(i.strip().split('_'))\n",
    "    cell_ids.append(i.strip().split('_')[leng-2])\n",
    "    Y = cci.download_raw_array(i)\n",
    "    cell_size += Y.shape[0]\n",
    "print cell_size \n",
    "print cell_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = np.zeros((cell_size,512,512,3))\n",
    "start = 0\n",
    "count=0\n",
    "for cid in cell_ids:\n",
    "    if count == 0:\n",
    "        print(cid)\n",
    "        X = cci.download_raw_array('Analysis/'+cell+'/'+cell+'_'+cid+'_X.npy')\n",
    "        S = COO.from_numpy(X)\n",
    "        Y = cci.download_raw_array('Analysis/'+cell+'/'+cell+'_'+cid+'_Y.npy') \n",
    "        count+=1\n",
    "    else:\n",
    "        print(cid)\n",
    "        x = cci.download_raw_array('Analysis/'+cell+'/'+cell+'_'+cid+'_X.npy')\n",
    "        s = COO.from_numpy(x)\n",
    "        size = S.shape[0]+s.shape[0]\n",
    "        print S.coords.shape\n",
    "        print s.coords.shape\n",
    "        coords = np.hstack((S.coords,s.coords))\n",
    "        data = np.hstack((S.data,s.data))\n",
    "        S = sparse.COO(coords, data, shape=(size,512,512,3))\n",
    "        y = cci.download_raw_array('Analysis/'+cell+'/'+cell+'_'+cid+'_Y.npy')\n",
    "        Y = np.append(Y,y)\n",
    "        print S.shape\n",
    "        print Y.shape\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_response3 = cci.upload_pickle('Analysis/'+cell+'/'+cell+'_sparse.npy', S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import glob, os, gc, sys\n",
    "import os.path\n",
    "import csv\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from time import time\n",
    "from subprocess import (call, Popen, PIPE)\n",
    "from itertools import product\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "from IPython.display import Image as IPImage\n",
    "import shutil\n",
    "import re\n",
    "import xml.etree.ElementTree as ET\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.layers import Input \n",
    "from keras.preprocessing import image\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Lambda, concatenate\n",
    "from keras import Model\n",
    "from keras.models import load_model\n",
    "\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "#model = load_model('/home/ubuntu/salk-logg-bsmn/efs/BSMN_Project/slav_incv3_scratch_25.h5')\n",
    "\n",
    "# parallel_model = multi_gpu_model(model, gpus=8)\n",
    "# opt = Adam(lr=0.001, beta_1=0.9, beta_2=0.999,epsilon=1e-08, decay=0.0)\n",
    "# parallel_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#opt = Adam(lr=0.001, beta_1=0.9, beta_2=0.999,epsilon=1e-08, decay=0.0)\n",
    "#model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "input_tensor = Input(shape=(512, 512, 3))  # this assumes K.image_data_format() == 'channels_last'\n",
    "\n",
    "base_model = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
    "\n",
    "\n",
    "#base_model=VGG19(include_top=False, weights='imagenet', pooling=None, input_shape=(256,256,3))\n",
    "base_model.summary()\n",
    "\n",
    "x=base_model.output\n",
    "x = Flatten(name='flatten')(x)\n",
    "x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "preds = Dense(512, activation='softmax', name='predictions')(x)\n",
    "\n",
    "feat_extractor = Model(inputs=base_model.input,outputs=preds)\n",
    "\n",
    "feat_extractor.summary()\n",
    "\n",
    "#inception_model = InceptionV3(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dset in Data_Sets:    \n",
    "    for cell in dset[0]:\n",
    "        print(cell)\n",
    "        if os.path.isfile(os.path.join(cellpath, cell, cell+'.npz')):\n",
    "            #try:\n",
    "                data = np.load(os.path.join(cellpath, cell, cell+'.npz'))\n",
    "                X = data['X'] / 255\n",
    "                Y = data['Y']\n",
    "                #Y = Y[:,np.r_[0:21,33:37]]\n",
    "                print(X.shape)\n",
    "                Z = feat_extractor.predict(X, batch_size = 32)\n",
    "                print(Z.shape)\n",
    "                np.savez(os.path.join(cellpath, cell, cell+'_Features.npz'), Z=Z)\n",
    "            #except: \n",
    "             #   print(\"npz is bad\")\n",
    "              #  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed('All_Cell_Data', X=X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from MulticoreTSNE import MulticoreTSNE as TSNE\n",
    "#from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components=2, verbose=2, perplexity=40, n_iter=3000, n_jobs=16)\n",
    "tsne_results = tsne.fit_transform(features)\n",
    "tx, ty = tsne_results[:,0], tsne_results[:,1]\n",
    "tx = (tx-np.min(tx)) / (np.max(tx) - np.min(tx))\n",
    "ty = (ty-np.min(ty)) / (np.max(ty) - np.min(ty))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (20,20)\n",
    "plt.scatter(tsne_results[:, 0], tsne_results[:, 1], alpha=0.8, s=8)\n",
    "plt.axis('equal');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(basepath,'tsneResults.npy'), tsne_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_results = np.load(os.path.join(basepath,'tsneResults.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "db = DBSCAN(min_samples=50, eps=1.7,n_jobs=16,algorithm='auto', leaf_size=30, metric='euclidean').fit(tsne_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "core_samples_mask[db.core_sample_indices_] = True\n",
    "labels = db.labels_\n",
    "\n",
    "# Number of clusters in labels, ignoring noise if present.\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "\n",
    "unique_labels = set(labels)\n",
    "colors = [plt.cm.Spectral(each)\n",
    "          for each in np.linspace(0, 1, len(unique_labels))]\n",
    "for k, col in zip(unique_labels, colors):\n",
    "    if k == -1:\n",
    "        # Black used for noise.\n",
    "        col = [0, 0, 0, 1]\n",
    "\n",
    "    class_member_mask = (labels == k)\n",
    "\n",
    "    xy = tsne_results[class_member_mask & core_samples_mask]\n",
    "    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
    "             markeredgecolor='k', markersize=8)\n",
    "\n",
    "    xy = tsne_results[class_member_mask & ~core_samples_mask]\n",
    "    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
    "             markeredgecolor='k', markersize=1)\n",
    "plt.rcParams[\"figure.figsize\"] = (50,50)\n",
    "plt.title('Estimated number of clusters: %d' % n_clusters_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels[labels == 16].shape)\n",
    "print(tsne_results[labels == 16].shape)\n",
    "print(X[labels == 16].shape)\n",
    "labels[labels == 16].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "def visualize_scatter_with_images(X_2d_data, images, figsize=(100,100), image_zoom=.1):\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    artists = []\n",
    "    for xy, i in zip(X_2d_data, images):\n",
    "        x0, y0 = xy\n",
    "        img = OffsetImage(i, zoom=image_zoom)\n",
    "        ab = AnnotationBbox(img, (x0, y0), xycoords='data', frameon=False)\n",
    "        artists.append(ax.add_artist(ab))\n",
    "    ax.update_datalim(X_2d_data)\n",
    "    ax.autoscale()\n",
    "    plt.show()\n",
    "\n",
    "visualize_scatter_with_images(tsne_results, images = X, image_zoom=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "def visualize_scatter_with_images(X_2d_data, images, figsize=(100,100), image_zoom=1):\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    artists = []\n",
    "    for xy, i in zip(X_2d_data, images):\n",
    "        x0, y0 = xy\n",
    "        img = OffsetImage(i, zoom=image_zoom)\n",
    "        ab = AnnotationBbox(img, (x0, y0), xycoords='data', frameon=False)\n",
    "        artists.append(ax.add_artist(ab))\n",
    "    ax.update_datalim(X_2d_data)\n",
    "    ax.autoscale()\n",
    "    plt.show()\n",
    "\n",
    "visualize_scatter_with_images(tsne_results[labels == 5], images = X[labels == 5], image_zoom=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_scatter_with_images(tsne_results[labels == 1], images = X[labels == 1], image_zoom=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visualize_scatter_with_images(tsne_results[labels == 2], images = X[labels == 2], image_zoom=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visualize_scatter_with_images(tsne_results[labels == 3], images = X[labels == 3], image_zoom=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_scatter_with_images(tsne_results[labels == 4], images = X[labels == 4], image_zoom=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_scatter_with_images(tsne_results[labels == 5], images = X[labels == 5], image_zoom=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_scatter_with_images(tsne_results[labels == 6], images = X[labels == 6], image_zoom=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_scatter_with_images(tsne_results[labels == 7], images = X[labels == 7], image_zoom=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_scatter_with_images(tsne_results[labels == 8], images = X[labels == 8], image_zoom=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_scatter_with_images(tsne_results[labels == 9], images = X[labels == 9], image_zoom=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_scatter_with_images(tsne_results[labels == 10], images = X[labels == 10], image_zoom=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_scatter_with_images(tsne_results[labels == 11], images = X[labels == 11], image_zoom=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_scatter_with_images(tsne_results[labels == 12], images = X[labels == 12], image_zoom=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_scatter_with_images(tsne_results[labels == 13], images = X[labels == 13], image_zoom=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_scatter_with_images(tsne_results[labels == 14], images = X[labels == 14], image_zoom=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_scatter_with_images(tsne_results[labels == 15], images = X[labels == 15], image_zoom=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_scatter_with_images(tsne_results[labels == 16], images = X[labels == 16], image_zoom=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function  # for Python2\n",
    "for var, obj in locals().items():\n",
    "    print(var, sys.getsizeof(obj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p27)",
   "language": "python",
   "name": "conda_tensorflow_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
