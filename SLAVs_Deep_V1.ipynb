{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import sys\n",
    "import glob, os, gc\n",
    "import cottoncandy as cc\n",
    "import uuid\n",
    "import os.path\n",
    "import csv\n",
    "import numpy as np\n",
    "from time import time\n",
    "from subprocess import (call, Popen, PIPE)\n",
    "from itertools import product\n",
    "from IPython.display import Image\n",
    "from PIL import Image\n",
    "from IPython.display import Image as IPImage\n",
    "import shutil\n",
    "import re\n",
    "import xml.etree.ElementTree as ET \n",
    "\n",
    "####convert bed to loci file\n",
    "\n",
    "##Path to Data\n",
    "basepath = \"/home/ubuntu/Analysis/\"\n",
    "cellpath = \"/home/ubuntu/Analysis/\"\n",
    "genome_regions = \"hs37d5_15K_Windows.bed\"\n",
    "L1HS = \"/home/ubuntu/Analysis/rmask_L1HS_Correct.bed\"\n",
    "L1HS_bam = \"-L1HS_mapped.bam\"\n",
    "L1HS_bam_bai = \"-L1HS_mapped.bam.bai\"\n",
    "bam = \"-ready.bam\"\n",
    "igv = \"-igv.xml\"\n",
    "bed = \".bed\"\n",
    "coverage15k = \".coverage15k\"\n",
    "coverage15k_gt100 = \".coverage15kgt100\"\n",
    "coverage15k_gt500 = \".coverage15kgt500\"\n",
    "loci = \".loci\"\n",
    "##IGV Template\n",
    "IGV = \"/home/ubuntu/Analysis/IGV_template.xml\"\n",
    "\n",
    "##Common Data\n",
    "Bulk_Brain_Common = \"04132016_mw_Bulk_cor\"\n",
    "Bulk_Fibro_Common = \"05252016_mw_Bulk_fib\"\n",
    "SC_MDA_Common = [\"04132016_mw_L1B1_SC_A2_S43\",\"04132016_mw_L1B1_SC_C1_S45\",\"04132016_mw_L1B1_SC_C2_S46\",\"04132016_mw_L1B1_SC_D2_S50\",\"04132016_mw_L1B1_SC_E2_S51\",\"04132016_mw_L1B1_SC_E3_S52\",\"04132016_mw_L1B1_SC_F2_S53\",\"04132016_mw_L1B1_SC_G1_S54\",\"04132016_mw_L1B1_SC_H1_S55\",\"05252016_mw_L1B1_SC_B4_S47\"] \n",
    "\n",
    "Data_Sets = []\n",
    "Data_Sets.append([SC_MDA_Common,Bulk_Brain_Common,Bulk_Fibro_Common])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hs37d5.genome\n",
      "hs37d5_15K_Windows.bed\n",
      "k100.umap.wg\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-5efb7b157152>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms3_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0ms3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mboto3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m's3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0ms3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'longboard-data'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/boto3/s3/inject.pyc\u001b[0m in \u001b[0;36mdownload_file\u001b[0;34m(self, Bucket, Key, Filename, ExtraArgs, Callback, Config)\u001b[0m\n\u001b[1;32m    170\u001b[0m         return transfer.download_file(\n\u001b[1;32m    171\u001b[0m             \u001b[0mbucket\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBucket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mKey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             extra_args=ExtraArgs, callback=Callback)\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/boto3/s3/transfer.pyc\u001b[0m in \u001b[0;36mdownload_file\u001b[0;34m(self, bucket, key, filename, extra_args, callback)\u001b[0m\n\u001b[1;32m    305\u001b[0m             bucket, key, filename, extra_args, subscribers)\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m         \u001b[0;31m# This is for backwards compatibility where when retries are\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0;31m# exceeded we need to throw the same error from boto3 instead of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/s3transfer/futures.pyc\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcancel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcancel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from boto3.session import Session\n",
    "import boto3\n",
    "\n",
    "ACCESS_KEY = 'AKIAJNNOA6QMT7HXF6GA'\n",
    "SECRET_KEY = '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'\n",
    "\n",
    "session = Session(aws_access_key_id=ACCESS_KEY,aws_secret_access_key=SECRET_KEY)\n",
    "s3 = session.resource('s3')\n",
    "your_bucket = s3.Bucket('longboard-sc')\n",
    "\n",
    "for s3_file in your_bucket.objects.all():\n",
    "    print(s3_file.key)\n",
    "    key = s3_file.key\n",
    "    s3 = boto3.client ('s3')\n",
    "    s3.download_file('longboard-sc',key,key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cci = cc.get_interface('salk-logg-bsmn', ACCESS_KEY='AKIAJNNOA6QMT7HXF6GA', SECRET_KEY='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', endpoint_url='https://s3-us-west-1.amazonaws.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##make XML file for each cell to use with igv_plotter\n",
    "for dset in Data_Sets:\n",
    "    for cell in dset[0]:\n",
    "        print cell\n",
    "        tree = ET.parse(IGV)\n",
    "        root = tree.getroot()\n",
    "        root[0][0].set('path', os.path.join(cellpath,  cell, cell + bam)) #sc bam\n",
    "        root[0][1].set('path', os.path.join(cellpath,  cell, cell + L1HS_bam)) #L1HS bam\n",
    "        root[1][0].set('id', os.path.join(cellpath,  cell, cell + bam)) #sc bam\n",
    "        root[2][0].set('id', os.path.join(cellpath,  cell, cell + L1HS_bam)) #L1HS bam\n",
    "        tree.write(os.path.join(cellpath,  cell, cell + igv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dset in Data_Sets:\n",
    "    for cell in dset[0]:\n",
    "        print cell\n",
    "        myoutput = open(os.path.join(cellpath, cell, cell + L1HS_bam), 'w')\n",
    "        p1 = Popen(['java', '-jar', '/home/ubuntu/jvarkit/dist/samviewwithmate.jar', '-b', L1HS, '--samoutputformat', 'BAM', os.path.join(cellpath,  cell, cell + bam)], stdout=myoutput)\n",
    "        p1.wait()\n",
    "        myoutput.close()\n",
    "        \n",
    "        p2 = Popen(['samtools', 'index', os.path.join(cellpath, cell, cell + L1HS_bam)])\n",
    "        p2.wait()\n",
    "        \n",
    "        myoutput2 = open(os.path.join(cellpath, cell, cell + coverage15k), 'w')\n",
    "        p3 = Popen(['bedtools', 'multicov', '-bams', os.path.join(cellpath, cell, cell + bam), '-bed', os.path.join(basepath,genome_regions)], stdout=myoutput2)\n",
    "        p3.wait()\n",
    "        myoutput2.close()\n",
    "        \n",
    "        myinput3 = open(os.path.join(cellpath, cell, cell + coverage15k), 'r')\n",
    "        myoutput3 = open(os.path.join(cellpath, cell, cell + coverage15k_gt100), 'w') \n",
    "        awk_cmd = \"{ if ($4 > 100) { print } }\"\n",
    "        proc = Popen(['awk', awk_cmd], stdin=myinput3, stdout=myoutput3)  \n",
    "        proc.wait()\n",
    "        myoutput3.flush()\n",
    "        \n",
    "        myinput_loci = os.path.join(cellpath, cell, cell + coverage15k_gt100)\n",
    "        myoutput_loci = os.path.join(cellpath, cell, cell + loci)\n",
    "        #regioncount = 0\n",
    "        with open(myoutput_loci, 'w') as outfile:\n",
    "            with open(myinput_loci, 'r') as infile:\n",
    "                data = infile.readlines()\n",
    "                for region in data:\n",
    "                    #regioncount += 1\n",
    "                    row = [str(region.strip().split('\\t')[0]),\":\",str(region.strip().split('\\t')[1]),\"-\",str(region.strip().split('\\t')[2])]  \n",
    "                    outfile.write(\"\".join(row)+'\\n')\n",
    "        #print regioncount\n",
    "        Popen(['split', '-l', '100', '-d', os.path.join(cellpath, cell, cell + loci), os.path.join(cellpath,  cell, cell + \".locisplit\")]).wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cci = cc.get_interface('salk-logg-bsmn', ACCESS_KEY='AKIAJNNOA6QMT7HXF6GA', SECRET_KEY='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', endpoint_url='https://s3-us-west-1.amazonaws.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for dset in Data_Sets:    \n",
    "    for cell in dset[0]:\n",
    "        print cell\n",
    "        cell_ids = []\n",
    "        os.chdir(os.path.join(cellpath, cell))    \n",
    "        locifile = os.path.join(cellpath, cell, cell + loci)\n",
    "        worklist = glob.glob(\"*.locisplit*\")\n",
    "        batchsize = 1\n",
    "        print len(worklist)\n",
    "        for i in xrange(187, len(worklist), batchsize):\n",
    "            batch = worklist[i:i+batchsize]\n",
    "            print i\n",
    "            index = 1\n",
    "            procs = []\n",
    "            for file in batch:\n",
    "                print file\n",
    "                with open(os.path.join(cellpath, cell, file)) as f0:\n",
    "                    first = f0.readline()# Read the first line.\n",
    "                    for last in f0: pass\n",
    "                    firstpic = cell+\"*\"+first.strip().split(':')[0]+\"_\"+first.strip().split(':')[1].split('-')[0]+\"_\"+first.strip().split(':')[1].split('-')[1]+\".png\"\n",
    "                    lastpic = cell+\"*\"+last.strip().split(':')[0]+\"_\"+last.strip().split(':')[1].split('-')[0]+\"_\"+last.strip().split(':')[1].split('-')[1]+\".png\"\n",
    "                    if not (glob.glob(os.path.join(basepath, cell, firstpic)) or glob.glob(os.path.join(basepath, cell, lastpic))): \n",
    "                        p = Popen(['igv_plotter', '-o', cell+\"_\", '-L', file, '-v', '--max-panel-height', '1000', '--igv-jar-path', '/home/ubuntu/Analysis/IGV_2.4.10/igv.jar', '-m', '6G', '-g', 'hg19', os.path.join(cellpath, cell, cell + igv)])\n",
    "                        procs.append(p)\n",
    "            for pp in procs:\n",
    "                pp.wait()\n",
    "            for file in glob.glob(\"*s*__*.png\"):\n",
    "                newfile = re.sub(\"_s\\d+__\", \"-\", file)\n",
    "                shutil.move(file, newfile)\n",
    "            for file in glob.glob(\"*.png\"):\n",
    "                if \"mod\" not in file:\n",
    "                    path = os.path.splitext(file)[0]\n",
    "                    basename = os.path.basename(path)\n",
    "                    outfile1 = basename + \"_mod.png\"\n",
    "                    if not os.path.isfile(os.path.join(cellpath,cell,outfile1)):               \n",
    "                        img = Image.open(file)\n",
    "                        pixelMap = img.load()\n",
    "                        img2 = Image.new(img.mode, img.size)\n",
    "                        pixelsNew = img2.load()\n",
    "                        for i in range(img2.size[0]):\n",
    "                            for j in range(img2.size[1]):\n",
    "                                if 250 in pixelMap[i,j]:\n",
    "                                    pixelMap[i,j] = (0,0,0,0)\n",
    "                                else:\n",
    "                                    pixelsNew[i,j] = pixelMap[i,j]\n",
    "                    img2.crop((174,130,img.size[0]-22,img.size[1])).resize((512,512)).save(outfile1)    \n",
    "            filelist = glob.glob(\"*_mod.png\")        \n",
    "            x = np.array([np.array(Image.open(fname)) for fname in filelist])\n",
    "            y = np.array([np.array(fname).astype(str) for fname in filelist])\n",
    "            uid = uuid.uuid4()\n",
    "            cell_ids.append(uid.hex)\n",
    "            print x.shape\n",
    "            print y.shape\n",
    "            s3_response1 = cci.upload_raw_array('Analysis/'+cell+'/'+cell+'_'+uid.hex+'_X.npy', x, gzip=True)\n",
    "            s3_response2 = cci.upload_raw_array('Analysis/'+cell+'/'+cell+'_'+uid.hex+'_Y.npy', y, gzip=True)\n",
    "            print s3_response1\n",
    "            print s3_response2\n",
    "            for file in glob.glob(\"*.png\"):\n",
    "                os.remove(file)\n",
    "            del x\n",
    "            del y\n",
    "            s3_response3 = cci.upload_raw_array('Analysis/'+cell+'/'+cell+'_IDs.npy', np.array(cell_ids))\n",
    "            print s3_response3\n",
    "            print \"Done with Sample: \"+cell\n",
    "            ##store unique npy ids for clarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid = uuid.uuid4()\n",
    "print uid.hex\n",
    "cell_ids.append(uid.hex)\n",
    "print cell_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cell = SC_MDA_Common[0]\n",
    "cell_size=0\n",
    "cell_ids = []\n",
    "cell_list=cci.glob(\"Analysis/\"+cell+\"*_Y.npy\")\n",
    "for i in cell_list:   \n",
    "    leng = len(i.strip().split('_'))\n",
    "    cell_ids.append(i.strip().split('_')[leng-2])\n",
    "    Y = cci.download_raw_array(i)\n",
    "    cell_size += Y.shape[0]\n",
    "print cell_size \n",
    "print cell_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = np.zeros((cell_size,512,512,3))\n",
    "start = 0\n",
    "count=0\n",
    "for cid in cell_ids:\n",
    "    if count == 0:\n",
    "        print(cid)\n",
    "        X = cci.download_raw_array('Analysis/'+cell+'/'+cell+'_'+cid+'_X.npy')\n",
    "        S = COO.from_numpy(X)\n",
    "        Y = cci.download_raw_array('Analysis/'+cell+'/'+cell+'_'+cid+'_Y.npy') \n",
    "        count+=1\n",
    "    else:\n",
    "        print(cid)\n",
    "        x = cci.download_raw_array('Analysis/'+cell+'/'+cell+'_'+cid+'_X.npy')\n",
    "        s = COO.from_numpy(x)\n",
    "        size = S.shape[0]+s.shape[0]\n",
    "        print S.coords.shape\n",
    "        print s.coords.shape\n",
    "        coords = np.hstack((S.coords,s.coords))\n",
    "        data = np.hstack((S.data,s.data))\n",
    "        S = sparse.COO(coords, data, shape=(size,512,512,3))\n",
    "        y = cci.download_raw_array('Analysis/'+cell+'/'+cell+'_'+cid+'_Y.npy')\n",
    "        Y = np.append(Y,y)\n",
    "        print S.shape\n",
    "        print Y.shape\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_response3 = cci.upload_pickle('Analysis/'+cell+'/'+cell+'_sparse.npy', S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import glob, os, gc, sys\n",
    "import os.path\n",
    "import csv\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from time import time\n",
    "from subprocess import (call, Popen, PIPE)\n",
    "from itertools import product\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "from IPython.display import Image as IPImage\n",
    "import shutil\n",
    "import re\n",
    "import xml.etree.ElementTree as ET\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.layers import Input \n",
    "from keras.preprocessing import image\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Lambda, concatenate\n",
    "from keras import Model\n",
    "from keras.models import load_model\n",
    "\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "#model = load_model('/home/ubuntu/salk-logg-bsmn/efs/BSMN_Project/slav_incv3_scratch_25.h5')\n",
    "\n",
    "# parallel_model = multi_gpu_model(model, gpus=8)\n",
    "# opt = Adam(lr=0.001, beta_1=0.9, beta_2=0.999,epsilon=1e-08, decay=0.0)\n",
    "# parallel_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#opt = Adam(lr=0.001, beta_1=0.9, beta_2=0.999,epsilon=1e-08, decay=0.0)\n",
    "#model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "input_tensor = Input(shape=(512, 512, 3))  # this assumes K.image_data_format() == 'channels_last'\n",
    "\n",
    "base_model = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
    "\n",
    "\n",
    "#base_model=VGG19(include_top=False, weights='imagenet', pooling=None, input_shape=(256,256,3))\n",
    "base_model.summary()\n",
    "\n",
    "x=base_model.output\n",
    "x = Flatten(name='flatten')(x)\n",
    "x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "preds = Dense(512, activation='softmax', name='predictions')(x)\n",
    "\n",
    "feat_extractor = Model(inputs=base_model.input,outputs=preds)\n",
    "\n",
    "feat_extractor.summary()\n",
    "\n",
    "#inception_model = InceptionV3(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dset in Data_Sets:    \n",
    "    for cell in dset[0]:\n",
    "        print(cell)\n",
    "        if os.path.isfile(os.path.join(cellpath, cell, cell+'.npz')):\n",
    "            #try:\n",
    "                data = np.load(os.path.join(cellpath, cell, cell+'.npz'))\n",
    "                X = data['X'] / 255\n",
    "                Y = data['Y']\n",
    "                #Y = Y[:,np.r_[0:21,33:37]]\n",
    "                print(X.shape)\n",
    "                Z = feat_extractor.predict(X, batch_size = 32)\n",
    "                print(Z.shape)\n",
    "                np.savez(os.path.join(cellpath, cell, cell+'_Features.npz'), Z=Z)\n",
    "            #except: \n",
    "             #   print(\"npz is bad\")\n",
    "              #  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed('All_Cell_Data', X=X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from MulticoreTSNE import MulticoreTSNE as TSNE\n",
    "#from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components=2, verbose=2, perplexity=40, n_iter=3000, n_jobs=16)\n",
    "tsne_results = tsne.fit_transform(features)\n",
    "tx, ty = tsne_results[:,0], tsne_results[:,1]\n",
    "tx = (tx-np.min(tx)) / (np.max(tx) - np.min(tx))\n",
    "ty = (ty-np.min(ty)) / (np.max(ty) - np.min(ty))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (20,20)\n",
    "plt.scatter(tsne_results[:, 0], tsne_results[:, 1], alpha=0.8, s=8)\n",
    "plt.axis('equal');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(basepath,'tsneResults.npy'), tsne_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_results = np.load(os.path.join(basepath,'tsneResults.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "db = DBSCAN(min_samples=50, eps=1.7,n_jobs=16,algorithm='auto', leaf_size=30, metric='euclidean').fit(tsne_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "core_samples_mask[db.core_sample_indices_] = True\n",
    "labels = db.labels_\n",
    "\n",
    "# Number of clusters in labels, ignoring noise if present.\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "\n",
    "unique_labels = set(labels)\n",
    "colors = [plt.cm.Spectral(each)\n",
    "          for each in np.linspace(0, 1, len(unique_labels))]\n",
    "for k, col in zip(unique_labels, colors):\n",
    "    if k == -1:\n",
    "        # Black used for noise.\n",
    "        col = [0, 0, 0, 1]\n",
    "\n",
    "    class_member_mask = (labels == k)\n",
    "\n",
    "    xy = tsne_results[class_member_mask & core_samples_mask]\n",
    "    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
    "             markeredgecolor='k', markersize=8)\n",
    "\n",
    "    xy = tsne_results[class_member_mask & ~core_samples_mask]\n",
    "    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
    "             markeredgecolor='k', markersize=1)\n",
    "plt.rcParams[\"figure.figsize\"] = (50,50)\n",
    "plt.title('Estimated number of clusters: %d' % n_clusters_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels[labels == 16].shape)\n",
    "print(tsne_results[labels == 16].shape)\n",
    "print(X[labels == 16].shape)\n",
    "labels[labels == 16].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "def visualize_scatter_with_images(X_2d_data, images, figsize=(100,100), image_zoom=.1):\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    artists = []\n",
    "    for xy, i in zip(X_2d_data, images):\n",
    "        x0, y0 = xy\n",
    "        img = OffsetImage(i, zoom=image_zoom)\n",
    "        ab = AnnotationBbox(img, (x0, y0), xycoords='data', frameon=False)\n",
    "        artists.append(ax.add_artist(ab))\n",
    "    ax.update_datalim(X_2d_data)\n",
    "    ax.autoscale()\n",
    "    plt.show()\n",
    "\n",
    "visualize_scatter_with_images(tsne_results, images = X, image_zoom=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "def visualize_scatter_with_images(X_2d_data, images, figsize=(100,100), image_zoom=1):\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    artists = []\n",
    "    for xy, i in zip(X_2d_data, images):\n",
    "        x0, y0 = xy\n",
    "        img = OffsetImage(i, zoom=image_zoom)\n",
    "        ab = AnnotationBbox(img, (x0, y0), xycoords='data', frameon=False)\n",
    "        artists.append(ax.add_artist(ab))\n",
    "    ax.update_datalim(X_2d_data)\n",
    "    ax.autoscale()\n",
    "    plt.show()\n",
    "\n",
    "visualize_scatter_with_images(tsne_results[labels == 5], images = X[labels == 5], image_zoom=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_scatter_with_images(tsne_results[labels == 1], images = X[labels == 1], image_zoom=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visualize_scatter_with_images(tsne_results[labels == 2], images = X[labels == 2], image_zoom=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visualize_scatter_with_images(tsne_results[labels == 3], images = X[labels == 3], image_zoom=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_scatter_with_images(tsne_results[labels == 4], images = X[labels == 4], image_zoom=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_scatter_with_images(tsne_results[labels == 5], images = X[labels == 5], image_zoom=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_scatter_with_images(tsne_results[labels == 6], images = X[labels == 6], image_zoom=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_scatter_with_images(tsne_results[labels == 7], images = X[labels == 7], image_zoom=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_scatter_with_images(tsne_results[labels == 8], images = X[labels == 8], image_zoom=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_scatter_with_images(tsne_results[labels == 9], images = X[labels == 9], image_zoom=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_scatter_with_images(tsne_results[labels == 10], images = X[labels == 10], image_zoom=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_scatter_with_images(tsne_results[labels == 11], images = X[labels == 11], image_zoom=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_scatter_with_images(tsne_results[labels == 12], images = X[labels == 12], image_zoom=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_scatter_with_images(tsne_results[labels == 13], images = X[labels == 13], image_zoom=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_scatter_with_images(tsne_results[labels == 14], images = X[labels == 14], image_zoom=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_scatter_with_images(tsne_results[labels == 15], images = X[labels == 15], image_zoom=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_scatter_with_images(tsne_results[labels == 16], images = X[labels == 16], image_zoom=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function  # for Python2\n",
    "for var, obj in locals().items():\n",
    "    print(var, sys.getsizeof(obj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
