{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04132016_mw_L1B1_SC_A2_S43\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import sys\n",
    "import glob, os, gc\n",
    "import uuid\n",
    "import os.path\n",
    "import csv\n",
    "import numpy as np\n",
    "from time import time\n",
    "from subprocess import (call, Popen, PIPE)\n",
    "from itertools import product\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import re\n",
    "import xml.etree.ElementTree as ET\n",
    "from boto3.session import Session\n",
    "import boto3\n",
    "import h5py\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.layers import Input \n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "##Path to Data\n",
    "basepath = \"/home/ubuntu/\"\n",
    "genome_regions = \"hs37d5_15K_Windows.bed\"\n",
    "L1HS_bam = \"-L1HS_mapped.bam\"\n",
    "L1HS_bam_bai = \"-L1HS_mapped.bam.bai\"\n",
    "L1HS = \"/home/ubuntu/rmask_L1HS_Correct.bed\"\n",
    "bam = \"-ready.bam\"\n",
    "bai = \"-ready.bam.bai\"\n",
    "igv = \"-igv.xml\"\n",
    "bed = \".bed\"\n",
    "coverage15k = \".coverage15k\"\n",
    "coverage15k_gt100 = \".coverage15kgt100\"\n",
    "loci = \".loci\"\n",
    "##IGV Template\n",
    "IGV = \"/home/ubuntu/longboard/IGV_template.xml\"\n",
    "subject = \"CommonSample\" #sys.argv[1]  #subjectid\n",
    "cell = \"04132016_mw_L1B1_SC_A2_S43\" #sys.argv[2] #input\n",
    "ACCESS_KEY = 'AKIAJNNOA6QMT7HXF6GA'\n",
    "SECRET_KEY = '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'\n",
    "print cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Load Data\n",
    "session = Session(aws_access_key_id=ACCESS_KEY,aws_secret_access_key=SECRET_KEY)\n",
    "s3 = session.resource('s3')\n",
    "your_bucket = s3.Bucket('longboard-sc')\n",
    "for s3_file in your_bucket.objects.all():\n",
    "    s3 = boto3.client ('s3')\n",
    "    s3.download_file('longboard-sc',s3_file.key,s3_file.key)\n",
    "#Bam\n",
    "s3.download_file('bsmn-data',os.path.join(subject, cell, cell + bam),os.path.join(basepath,cell + bam))\n",
    "s3.download_file('bsmn-data',os.path.join(subject, cell, cell + bai),os.path.join(basepath,cell + bai))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myoutput = open(os.path.join(basepath, cell + L1HS_bam), 'w')\n",
    "p1 = Popen(['java', '-jar', '/home/ubuntu/jvarkit/dist/samviewwithmate.jar', '-b', L1HS, '--samoutputformat', 'BAM', os.path.join(basepath, cell + bam)], stdout=myoutput)\n",
    "p1.wait()\n",
    "myoutput.close()\n",
    "\n",
    "p2 = Popen(['samtools', 'index', os.path.join(basepath, cell + L1HS_bam)])\n",
    "p2.wait()\n",
    "\n",
    "myoutput2 = open(os.path.join(basepath, cell + coverage15k), 'w')\n",
    "p3 = Popen(['bedtools', 'multicov', '-bams', os.path.join(basepath, cell + bam), '-bed', os.path.join(basepath,genome_regions)], stdout=myoutput2)\n",
    "p3.wait()\n",
    "myoutput2.close()\n",
    "\n",
    "myinput3 = open(os.path.join(basepath, cell + coverage15k), 'r')\n",
    "myoutput3 = open(os.path.join(basepath, cell + coverage15k_gt100), 'w')\n",
    "awk_cmd = \"{ if ($4 > 100) { print } }\"\n",
    "proc = Popen(['awk', awk_cmd], stdin=myinput3, stdout=myoutput3)\n",
    "proc.wait()\n",
    "myoutput3.flush()\n",
    "\n",
    "tree = ET.parse(IGV)\n",
    "root = tree.getroot()\n",
    "root[0][0].set('path', os.path.join(basepath, cell + bam)) #sc bam\n",
    "root[0][1].set('path', os.path.join(basepath, cell + L1HS_bam)) #L1HS bam\n",
    "root[1][0].set('id', os.path.join(basepath, cell + bam)) #sc bam\n",
    "root[2][0].set('id', os.path.join(basepath, cell + L1HS_bam)) #L1HS bam\n",
    "tree.write(os.path.join(basepath, cell + igv))\n",
    "\n",
    "myinput_loci = os.path.join(basepath, cell + coverage15k_gt100)\n",
    "myoutput_loci = os.path.join(basepath, cell + loci)\n",
    "with open(myoutput_loci, 'w') as outfile:\n",
    "\twith open(myinput_loci, 'r') as infile:\n",
    "        \tdata = infile.readlines()\n",
    "        \tfor region in data:\n",
    "                \trow = [str(region.strip().split('\\t')[0]),\":\",str(region.strip().split('\\t')[1]),\"-\",str(region.strip().split('\\t')[2])]\n",
    "                \toutfile.write(\"\".join(row)+'\\n')\n",
    "Popen(['split', '-l', '100', '-d', os.path.join(basepath, cell + loci), os.path.join(basepath, cell + \".locisplit\")]).wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/miniconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "input_tensor = Input(shape=(512, 512, 3))\n",
    "base_model = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
    "\n",
    "x=base_model.output\n",
    "x = Flatten(name='flatten')(x)\n",
    "x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "preds = Dense(512, activation='sigmoid', name='predictions')(x)\n",
    "\n",
    "feat_extractor = Model(inputs=base_model.input,outputs=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print cell\n",
    "cell_ids = []\n",
    "locifile = os.path.join(basepath, cell + loci)\n",
    "worklist = glob.glob(\"*.locisplit*\")\n",
    "batchsize = 16\n",
    "print len(worklist)\n",
    "session = Session(aws_access_key_id=ACCESS_KEY,aws_secret_access_key=SECRET_KEY)\n",
    "s3 = session.resource('s3')\n",
    "for i in xrange(0, len(worklist), batchsize):\n",
    "    batch = worklist[i:i+batchsize]\n",
    "    print i\n",
    "    index = 1\n",
    "    procs = []\n",
    "    for file in batch:\n",
    "        print file\n",
    "        with open(os.path.join(basepath, file)) as f0:\n",
    "            first = f0.readline()# Read the first line.\n",
    "            for last in f0: pass\n",
    "            firstpic = cell+\"-\"+\"*\"+first.strip().split(':')[0]+\"_\"+first.strip().split(':')[1].split('-')[0]+\"_\"+first.strip().split(':')[1].split('-')[1]+\".png\"\n",
    "            lastpic = cell+\"-\"+\"*\"+last.strip().split(':')[0]+\"_\"+last.strip().split(':')[1].split('-')[0]+\"_\"+last.strip().split(':')[1].split('-')[1]+\".png\"\n",
    "            if not (glob.glob(os.path.join(basepath, firstpic)) or glob.glob(os.path.join(basepath, lastpic))):\n",
    "                p = Popen(['igv_plotter', '-o', cell+\"_\", '-L', file, '-v', '--max-panel-height', '1000', '--igv-jar-path', '/home/ubuntu/IGV_2.4.10/igv.jar', '-m', '6G', '-g', 'hg19', os.path.join(basepath, cell + igv)])\n",
    "                procs.append(p)\n",
    "    for pp in procs:\n",
    "        pp.wait()\n",
    "    for file in glob.glob(\"*s*__*.png\"):\n",
    "        newfile = re.sub(\"_s\\d+__\", \"-\", file)\n",
    "        shutil.move(file, newfile)\n",
    "    for file in glob.glob(\"*.png\"):\n",
    "        if \"mod\" not in file:\n",
    "            path = os.path.splitext(file)[0]\n",
    "            basename = os.path.basename(path)\n",
    "            outfile1 = basename + \"_mod.png\"\n",
    "            if not os.path.isfile(os.path.join(basepath,outfile1)):\n",
    "                img = Image.open(file)\n",
    "                pixelMap = img.load()\n",
    "                img2 = Image.new(img.mode, img.size)\n",
    "                pixelsNew = img2.load()\n",
    "                for i in range(img2.size[0]):\n",
    "                    for j in range(img2.size[1]):\n",
    "                        if 250 in pixelMap[i,j]:\n",
    "                            pixelMap[i,j] = (0,0,0,0)\n",
    "                        else:\n",
    "                            pixelsNew[i,j] = pixelMap[i,j]\n",
    "            \timg2.crop((174,130,img.size[0]-22,img.size[1])).resize((512,512)).save(outfile1)\n",
    "    filelist = glob.glob(\"*_mod.png\")\n",
    "    x = np.array([np.array(Image.open(fname)) for fname in filelist])\n",
    "    x = x / 255\n",
    "    y = np.array([np.array(fname).astype(str) for fname in filelist])\n",
    "    uid = uuid.uuid4()\n",
    "    cell_ids.append(uid.hex)\n",
    "    print(uid.hex)\n",
    "    z = feat_extractor.predict(x, batch_size = 16)\n",
    "    hf = h5py.File(cell+'_'+uid.hex+'.h5', 'w')\n",
    "    hf.create_dataset('X', data=x)\n",
    "    hf.create_dataset('Y', data=y)\n",
    "    hf.create_dataset('Z', data=z)\n",
    "    hf.close()\n",
    "    s3.meta.client.upload_file(os.path.join(basepath,cell+'_'+uid.hex+'.h5'),'bsmn-data',os.path.join(subject, cell, cell+'_'+uid.hex+'.h5'))\n",
    "    for file in glob.glob(\"*.png\"):\n",
    "        os.remove(file)    \n",
    "    os.remove(os.path.join(basepath,cell+'_'+uid.hex+'.h5'))\n",
    "hf = h5py.File(cell+'_IDs.h5', 'w')\n",
    "hf.create_dataset('ID', data=cell_ids)\n",
    "hf.close()\n",
    "s3.meta.client.upload_file(os.path.join(basepath,cell+'_IDs.h5'),'bsmn-data',os.path.join(subject, cell, cell+'_IDs.h5'))\n",
    "print \"Done with Sample: \"+cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = Session(aws_access_key_id=ACCESS_KEY,aws_secret_access_key=SECRET_KEY)\n",
    "s3 = session.resource('s3')    \n",
    "print(cell)\n",
    "cell_size=0\n",
    "cell_ids = []\n",
    "s3.meta.client.download_file('bsmn-data',os.path.join(subject, cell, cell+'_IDs.h5'),os.path.join(basepath,cell+'_IDs.h5'))\n",
    "f = h5py.File(cell+'_IDs.h5', 'r')\n",
    "cell_ids = f['ID']\n",
    "count = 0\n",
    "for cid in cell_ids:\n",
    "    print(cid)\n",
    "    s3.meta.client.download_file('bsmn-data',os.path.join(subject, cell, cell+'_'+cid+'.h5'),os.path.join(basepath,cell+'_'+cid+'.h5'))\n",
    "    xyz = h5py.File(os.path.join(basepath,cell+'_'+cid+'.h5'), 'r')\n",
    "    os.remove(os.path.join(basepath,cell+'_'+cid+'.h5'))\n",
    "    if count == 0:\n",
    "        X = xyz['X']\n",
    "        Y = xyz['Y']\n",
    "        Z = xyz['Z']\n",
    "        count+=1\n",
    "    else:\n",
    "        X = np.append(X,xyz['X'], axis=0)\n",
    "        Y = np.append(Y,xyz['Y'], axis=0)\n",
    "        Z = np.append(Z,xyz['Z'], axis=0)\n",
    "        print(Z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MulticoreTSNE import MulticoreTSNE as TSNE\n",
    "#from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components=2, verbose=2, perplexity=35, n_iter=2000, n_jobs=16)\n",
    "tsne_results = tsne.fit_transform(Z)\n",
    "tx, ty = tsne_results[:,0], tsne_results[:,1]\n",
    "tx = (tx-np.min(tx)) / (np.max(tx) - np.min(tx))\n",
    "ty = (ty-np.min(ty)) / (np.max(ty) - np.min(ty))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (20,20)\n",
    "plt.scatter(tsne_results[:, 0], tsne_results[:, 1], alpha=0.8, s=8)\n",
    "plt.axis('equal');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "db = DBSCAN(min_samples=50, eps=2,n_jobs=16,algorithm='auto', leaf_size=30, metric='euclidean').fit(tsne_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "core_samples_mask[db.core_sample_indices_] = True\n",
    "labels = db.labels_\n",
    "\n",
    "# Number of clusters in labels, ignoring noise if present.\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "plt.rcParams[\"figure.figsize\"] = (20,20)\n",
    "unique_labels = set(labels)\n",
    "colors = [plt.cm.Spectral(each)\n",
    "          for each in np.linspace(0, 1, len(unique_labels))]\n",
    "for k, col in zip(unique_labels, colors):\n",
    "    if k == -1:\n",
    "        # Black used for noise.\n",
    "        col = [0, 0, 0, 1]\n",
    "\n",
    "    class_member_mask = (labels == k)\n",
    "\n",
    "    xy = tsne_results[class_member_mask & core_samples_mask]\n",
    "    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
    "             markeredgecolor='k', markersize=8)\n",
    "\n",
    "    xy = tsne_results[class_member_mask & ~core_samples_mask]\n",
    "    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
    "             markeredgecolor='k', markersize=1)\n",
    "plt.title('Estimated number of clusters: %d' % n_clusters_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "def visualize_scatter_with_images(X_2d_data, images, figsize=(100,100), image_zoom=.1):\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    artists = []\n",
    "    for xy, i in zip(X_2d_data, images):\n",
    "        x0, y0 = xy\n",
    "        img = OffsetImage(i, zoom=image_zoom)\n",
    "        ab = AnnotationBbox(img, (x0, y0), xycoords='data', frameon=False)\n",
    "        artists.append(ax.add_artist(ab))\n",
    "    ax.update_datalim(X_2d_data)\n",
    "    ax.autoscale()\n",
    "    plt.show()\n",
    "\n",
    "visualize_scatter_with_images(tsne_results, images = X, image_zoom=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04132016_mw_L1B1_SC_A2_S43\n",
      "98579e28a9584791b6b8472c39152550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda2/lib/python2.7/site-packages/h5py/_hl/dataset.py:313: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  \"Use dataset[()] instead.\", H5pyDeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8014a8c3e6cd40789788ae2e37d88ed8\n",
      "5c3b4f81fb6042f4b0a48f31821d9f2d\n",
      "2fca416f159646689bde191a1f84dd03\n",
      "ce3daa8cb8794720977febe877b7c867\n",
      "0033436567b74db4b74b134a03ddd5bb\n",
      "ea9f1c74fbb44b1ab98325148236bccd\n",
      "27bf4d7c8b9a48c19dd74cb1d1fb1d23\n"
     ]
    }
   ],
   "source": [
    "##modify existing h5 files\n",
    "session = Session(aws_access_key_id=ACCESS_KEY,aws_secret_access_key=SECRET_KEY)\n",
    "s3 = session.resource('s3')    \n",
    "print(cell)\n",
    "cell_size=0\n",
    "cell_ids = []\n",
    "s3.meta.client.download_file('bsmn-data',os.path.join(subject, cell, cell+'_IDs.h5'),os.path.join(basepath,cell+'_IDs.h5'))\n",
    "f = h5py.File(os.path.join(basepath,cell+'_IDs.h5'), 'r')\n",
    "cell_ids = f['ID'].value\n",
    "f.close()\n",
    "count = 0\n",
    "for cid in cell_ids:\n",
    "    print(cid)\n",
    "    s3.meta.client.download_file('bsmn-data',os.path.join(subject, cell, cell+'_'+cid+'.h5'),os.path.join(basepath,cell+'_'+cid+'.h5'))\n",
    "    xyz = h5py.File(os.path.join(basepath,cell+'_'+cid+'.h5'), 'r')\n",
    "    os.remove(os.path.join(basepath,cell+'_'+cid+'.h5'))\n",
    "    X = xyz['X'].value\n",
    "    X = X / 255\n",
    "    Y = xyz['Y'].value\n",
    "    xyz.close()\n",
    "    del xyz\n",
    "    hf = h5py.File(os.path.join(basepath,cell+'_'+cid+'.h5'), 'w')\n",
    "    hf.create_dataset('X', data=X)\n",
    "    hf.create_dataset('Y', data=Y)\n",
    "    z = feat_extractor.predict(X, batch_size = 16)\n",
    "    hf.create_dataset('Z', data=z)\n",
    "    hf.close()\n",
    "    s3.meta.client.upload_file(os.path.join(basepath,cell+'_'+cid+'.h5'),'bsmn-data',os.path.join(subject, cell, cell+'_'+cid+'.h5'))\n",
    "    os.remove(os.path.join(basepath,cell+'_'+cid+'.h5'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
